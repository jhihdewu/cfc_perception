# q3: 訓練 Segmentation Model

## CVAT安裝與佈署

1. 依照[官方教學](https://docs.cvat.ai/docs/administration/basics/installation/)使用docker跑cvat起來後照著教學做了一些簡單的操作。

2. 之後依照[教學](https://www.youtube.com/watch?v=xopaChA1xn0)設定好sam的整合，讓之後調整標注資料更有效率

## 貼標模型選擇

1. [Autodistill](https://github.com/autodistill/autodistill-grounded-sam-2)

   1. 曾經操作過，當時整合了許多sota的模型，還滿好用

   2. 遇到許多問題後決定放棄這個方向

      1. 各種dependencies問題

      2. 解決了後發現我想用的模組default實作會out of memory on 4060 laptop 8GB, 後來嘗試在2080 ti上跑但是突然遇到網速不明原因大幅下降，光是把ubuntu灌好就等了快2個小時，後來判斷再抓pytorch等等的會吃掉剩餘的時間因此決定使用colab

      3. 使用colab後還是遇到其他的dependency問題，判斷不能再花時間在這個lib上面，故放棄這個wrapper.

2. **[Grounded-SAM-2](https://github.com/IDEA-Research/Grounded-SAM-2)**

   1. 直接使用作者的程式碼，透過Docker安裝好後執行時有遇到問題，針對有用到以下程式碼的程式做修改後可以正常運作：

      1. before

         ```python
         torch.autocast(device_type="cuda", dtype=torch.bfloat16).__enter__()
         ```

      2. after

         ```python
         torch.autocast(device_type="cuda", dtype=torch.float16).__enter__()
         ```

   2. 跑官方的 **Grounded SAM 2 Image Demo** example沒問題

   3. 針對官方exmaple做修改，讓它最後可以直接產生yolo資料集供後續訓練使用

   4. 我的[fork](https://github.com/jhihdewu/Grounded-SAM-2)

   ## 資料篩選

   - 從整段影片4377張照片中，我人工刪除相近與模糊的照片後留下178張照片

   - 以80/20分，141張用於training set，36張用於validation set

   ## 模型訓練

   1. 首先直接使用Grounded-SAM-2輸出的label直接訓練100 epoch

      1. ipynp檔案在 dl/yolo_training_on_raw_grounded_sam2_label.ipynb

      2. 此模型的mAP50-95(M)的最好表現是在epoch 67為0.68407

      3. 詳細成果紀錄在dl/runs/segment/raw 中

   2. 之後我使用cvat針對這些label做以下改善：

      1. 刪除同一物件重複標示

      2. 刪除錯誤標示

      3. 增加沒有標到的物件

   3. 使用改善後的label做訓練，一樣是100 epoch

      1. ipynp檔案在  dl/yolo_training_on_processed_label.ipynb

      2. 此模型的mAP50-95(M)的最好表現是在epoch 72為0.80296

      3. 成果紀錄在dl/runs/segment/processed 中

   

